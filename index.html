<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Practical Machine Learning Project : Project for Coursera class from Data Science specialization.">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Practical Machine Learning Project</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/tinve/Machine-Learning-Project">View on GitHub</a>

          <h1 id="project_title">Practical Machine Learning Project</h1>
          <h2 id="project_tagline">Project for Coursera class from Data Science specialization.</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/tinve/Machine-Learning-Project/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/tinve/Machine-Learning-Project/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a id="practical-machine-learning-project" class="anchor" href="#practical-machine-learning-project" aria-hidden="true"><span class="octicon octicon-link"></span></a>Practical Machine learning project.</h3>

<h2>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background</h2>

<p>The data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, doing the set of exercises, was collected, processed and published by <a href="http://groupware.les.inf.puc-rio.br/har">this group</a>.
Participant were asked to perform barbell lifts correctly and incorrectly in 5 different ways (denoted by letters A, B, C, D or E). Training data set can be downloaded from <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">here</a>, and test data set - from <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">here</a> </p>

<h2>
<a id="data-cleaning" class="anchor" href="#data-cleaning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data cleaning</h2>

<p>I have downloaded both csv files into my working directory and uploaded them to R workspace as data frames. All empty fields were filled with NA. Outcome (A, B, C, D or E) is stored in "classe" column.</p>

<pre><code>library(caret)

## load datasets

full &lt;- read.csv("pml-training.csv", stringsAsFactors = TRUE,
                                     na.strings = c("", "NA"))
testing &lt;- read.csv("pml-testing.csv", stringsAsFactors = TRUE,
                                       na.strings = c("", "NA"))
</code></pre>

<p>Test set does not have answers, so I need cross validation to estimate model accuracy. The data set is large enough to split it into training (70%) and validation (30%) data sets, which are both still fairly large.
I also set seed for reproducibility.</p>

<pre><code># split full data set into training and validation

set.seed(123)
inTrain &lt;- createDataPartition(full$classe, p = 0.7, list = FALSE)
training &lt;- full[inTrain, ]
validation &lt;- full[-inTrain, ]
</code></pre>

<p>Not all variables in the data set would make good predictors. So first I make a list of variable names that I want to drop from the data.
Variables "X", "user_name", and "problem_id" should not affect the prediction. Since I build classification rather than forecasting model, I should also drop all variables related to time ("raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window" and "num_window").</p>

<pre><code># list of columns that should not affect the prediction

skipColumns &lt;- c("X", 
                 "user_name", 
                 "raw_timestamp_part_1", 
                 "raw_timestamp_part_2", 
                 "cvtd_timestamp", 
                 "new_window", 
                 "num_window",
                 "problem_id")
</code></pre>

<p>Some columns miss too many values. I am going to drop all columns that have more than 50% of values missing.</p>

<pre><code># add columns that miss more than half of the values in training dataset

for (i in 0:dim(training)[2])
    {
    if (sum(is.na(training[ , i])) &gt; 0.5 * length(training[ , i]))
        {
        skipColumns &lt;- c(skipColumns, names(training[i]))
        }
    }
</code></pre>

<p>Now that I have the full list of irrelevant variables, I can delete them from my data frames.</p>

<pre><code># reduce number of predictors

training &lt;- training[, ! names(training) %in% skipColumns]
validation &lt;- validation[, ! names(validation) %in% skipColumns]
testing &lt;- testing[, ! names(testing) %in% skipColumns]
</code></pre>

<h2>
<a id="model-building" class="anchor" href="#model-building" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model building</h2>

<p>I build random forest model on clean training data set. It shall predict "classe" based on all other variables in data frame.</p>

<pre><code># build a random forest model

modFit &lt;- train(classe ~ ., data = training, model = "rf")
</code></pre>

<p>I first want to check its accuracy on training data:</p>

<pre><code># run model on training data set, get accuracy on training set 

trainPrediction &lt;- predict(modFit, training)
print(confusionMatrix(training$classe, trainPrediction))
</code></pre>

<p>This is what I get (truncated for brevity):</p>

<pre><code>Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 3906    0    0    0    0
         B    0 2658    0    0    0
         C    0    0 2396    0    0
         D    0    0    0 2252    0
         E    0    0    0    0 2525

Overall Statistics

               Accuracy : 1          
                 95% CI : (0.9997, 1)
    No Information Rate : 0.2843     
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16  

                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
</code></pre>

<p>Not bad! The model predicts all the outcomes in training data with 100% accuracy. But this is not a correct estimate of the model accuracy, because the model might be overfitted on training dataset. 
I now apply my model to the validation data:</p>

<pre><code># run model on validation data set, estimate out of the sample error

validPrediction &lt;- predict(modFit, validation)
print(confusionMatrix(validation$classe, validPrediction))
</code></pre>

<p>As expected, the confusion matrix is no longer strictly diagonal, and accuracy is below 100%:</p>

<pre><code>Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1672    2    0    0    0
         B    7 1130    2    0    0
         C    0    8 1015    3    0
         D    0    0   17  946    1
         E    0    0    2    1 1079

Overall Statistics

               Accuracy : 0.9927          
                 95% CI : (0.9902, 0.9947)
    No Information Rate : 0.2853          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       

                  Kappa : 0.9908          
 Mcnemar's Test P-Value : NA          
</code></pre>

<p>Still, out of the sample error is less than 1%, so the model is pretty good!</p>

<h2>
<a id="submission" class="anchor" href="#submission" aria-hidden="true"><span class="octicon octicon-link"></span></a>Submission</h2>

<p>All that's left is to run the model on training set and write the answer for each of 20 cases into a separate file:</p>

<pre><code># run model on testing data set

answers &lt;- predict(modFit, testing)
print(answers)

# write answers to individual files

for(i in 1:length(answers)) {
    filename = paste0("problem_id_", i, ".txt")
    write.table(answers[i], file=filename,
                quote=FALSE, row.names=FALSE, col.names=FALSE)
}
</code></pre>

<p>Out of sample accuracy 99% and a little bit of luck is enough to get 20 out of 20:</p>

<pre><code> [1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E
</code></pre>

<p>The End.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Practical Machine Learning Project maintained by <a href="https://github.com/tinve">tinve</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
